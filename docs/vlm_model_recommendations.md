# Ollama VLMモデル推奨ガイド

## PCスペック
- **モデル**: MacBook Pro (Mac16,5)
- **CPU**: 16コア（12パフォーマンス + 4効率）
- **メモリ**: 128GB RAM

## 推奨VLMモデル

### 1. llava:13b（最推奨）
- **モデル名**: `llava:13b`
- **サイズ**: 約8.0GB
- **パラメータ数**: 13B
- **特徴**:
  - 高精度な画像理解能力
  - 複雑な視覚的タスクに対応
  - ゲシュタルト原則の評価に適している
- **メモリ要件**: 約16-20GB（動作に十分な余裕あり）
- **推奨理由**: 128GB RAMを活用でき、高い性能が期待できる

### 2. llava:latest / llava:7b（標準オプション）
- **モデル名**: `llava:latest` または `llava:7b`
- **サイズ**: 約4.7GB
- **パラメータ数**: 7B
- **特徴**:
  - LLaVA 1.6バージョンの最新モデル
  - より軽量で、処理速度が速い
  - バッチ処理時の利便性
- **メモリ要件**: 約10-12GB
- **用途**: 大量の画像を処理する場合や初期テストに適している

### 3. llava:34b（高精度オプション）
- **モデル名**: `llava:34b`
- **サイズ**: 約20GB
- **パラメータ数**: 34B
- **特徴**:
  - 最高精度のLLaVAモデル
  - 非常に高精度な画像理解能力
- **メモリ要件**: 約40-50GB
- **用途**: 最高精度が求められる場合（128GB RAMであれば動作可能）

## インストールコマンド

```bash
# 最推奨モデル（13Bモデル）
ollama pull llava:13b

# または、標準的な7Bモデル（LLaVA 1.6相当）
ollama pull llava:latest
# または
ollama pull llava:7b

# 高精度オプション（34Bモデル）
ollama pull llava:34b
```

## 推奨設定
- **最推奨**: `llava:13b` - 高い画像理解能力とバランスの取れた性能
- **用途**: ゲシュタルト原則の評価には、詳細な視覚理解が重要
- **理由**: 128GB RAMの強力なマシンで、高い性能を発揮できる

**注意**: `llava:latest`はLLaVA 1.6バージョンの7Bモデルです。`llava:1.6`というタグは存在しません。

## パフォーマンス比較（予想）

| モデル | 精度 | 速度 | メモリ使用量 | 推奨度 |
|--------|------|------|--------------|--------|
| llava:34b | ⭐⭐⭐⭐⭐ | ⭐⭐ | 40-50GB | ⭐⭐⭐⭐ |
| llava:13b | ⭐⭐⭐⭐ | ⭐⭐⭐ | 16-20GB | ⭐⭐⭐⭐⭐ |
| llava:latest/7b | ⭐⭐⭐ | ⭐⭐⭐⭐ | 10-12GB | ⭐⭐⭐⭐ |

## 注意事項
- すべてのモデルはM1/M2/M3チップで最適化されている
- 初回実行時はモデルのダウンロードが必要
- バッチ処理時は、メモリ使用量に注意（128GB RAMで問題なし）

